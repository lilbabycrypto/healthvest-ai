{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# HealthVest AI - Lab Report Analyzer\n\n**MedGemma Impact Challenge Submission**\n\nAn AI-powered lab report analyzer that helps Indian patients understand their blood test results in plain English.\n\n## Problem\n- Patients struggle to understand medical jargon in lab reports\n- Reference ranges are confusing without context\n- No easy way to track health trends over time\n\n## Solution\nUpload blood test report â†’ Get plain English explanations for each value\n\n## Key Features\n- Uses MedGemma 1.5 4B - Google's medical AI model\n- Extracts structured data from lab report images\n- Generates patient-friendly explanations\n- Supports Indian lab formats (Thyrocare, SRL, Dr. Lal PathLabs, Metropolis)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies (fix protobuf version conflict)\n!pip install -q transformers>=4.50.0 accelerate pillow pdf2image\n!pip install -q protobuf>=3.20\n\nimport warnings\nwarnings.filterwarnings('ignore')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport json\nfrom PIL import Image\nfrom transformers import pipeline\nimport os\n\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MedGemma Model\n",
    "\n",
    "Using MedGemma 1.5 4B - Google's open-source medical AI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Model configuration - MedGemma 1.5 4B (latest version)\nMODEL_ID = \"google/medgemma-1.5-4b-it\"\n\n# Get HF token from Kaggle secrets\n# IMPORTANT: In Kaggle, you must:\n# 1. Add secret: Settings (right panel) > Secrets > Add Secret > Name: \"HF_TOKEN\"\n# 2. ATTACH the secret: Toggle ON next to your HF_TOKEN secret\n# 3. Accept model license at: https://huggingface.co/google/medgemma-1.5-4b-it\n\nHF_TOKEN = None\n\n# Method 1: Kaggle Secrets (preferred)\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    HF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\n    print(\"HF_TOKEN loaded from Kaggle Secrets\")\nexcept Exception as e:\n    print(f\"Kaggle secrets error: {e}\")\n\n# Method 2: Environment variable fallback\nif not HF_TOKEN:\n    HF_TOKEN = os.environ.get('HF_TOKEN', None)\n    if HF_TOKEN:\n        print(\"HF_TOKEN loaded from environment\")\n\n# Method 3: Direct input (for testing only)\nif not HF_TOKEN:\n    print(\"ERROR: HF_TOKEN not found!\")\n    print(\"\\nTo fix this on Kaggle:\")\n    print(\"1. Right panel > Secrets > Add Secret\")\n    print(\"2. Name: HF_TOKEN, Value: your_token\")\n    print(\"3. TOGGLE ON the secret to attach it to notebook\")\n    print(\"4. Accept license: https://huggingface.co/google/medgemma-1.5-4b-it\")\nelse:\n    # Verify token works\n    print(f\"Token starts with: {HF_TOKEN[:10]}...\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load MedGemma using pipeline (recommended approach)\nprint(\"Loading MedGemma model (this takes 2-3 minutes on GPU)...\")\n\npipe = pipeline(\n    \"image-text-to-text\",\n    model=MODEL_ID,\n    token=HF_TOKEN,\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\n\nprint(\"MedGemma loaded successfully!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction Prompt\n",
    "\n",
    "Carefully crafted prompt for extracting lab values from Indian lab report formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACTION_PROMPT = \"\"\"You are a medical lab report analyzer. Extract all test values from this lab report image.\n",
    "\n",
    "For each test, provide:\n",
    "- test_name: Name of the test (e.g., \"Hemoglobin\", \"Fasting Blood Sugar\", \"TSH\")\n",
    "- value: Numeric value as shown\n",
    "- unit: Unit of measurement (e.g., \"g/dL\", \"mg/dL\", \"mIU/L\")\n",
    "- reference_range: Normal range as shown on report\n",
    "- status: \"normal\", \"high\", or \"low\" based on reference range\n",
    "\n",
    "Return ONLY a JSON array. Example:\n",
    "[\n",
    "  {\"test_name\": \"Hemoglobin\", \"value\": 14.2, \"unit\": \"g/dL\", \"reference_range\": \"13.0-17.0\", \"status\": \"normal\"}\n",
    "]\n",
    "\n",
    "Extract ALL tests visible. Use exact values. Handle Indian lab formats (Thyrocare, SRL, Dr. Lal PathLabs).\n",
    "\"\"\"\n",
    "\n",
    "EXPLANATION_PROMPT = \"\"\"You are a friendly medical educator. Explain this lab value simply:\n",
    "\n",
    "Test: {test_name}\n",
    "Value: {value} {unit}\n",
    "Normal Range: {reference_range}\n",
    "Status: {status}\n",
    "\n",
    "In under 80 words, explain:\n",
    "1. What this test measures\n",
    "2. What your result means\n",
    "3. One actionable tip (if needed)\n",
    "\n",
    "Use simple language. Never diagnose - suggest discussing with doctor if abnormal.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def extract_lab_values(image: Image.Image) -> list:\n    \"\"\"Extract lab values from a lab report image using MedGemma.\"\"\"\n    \n    # Resize if too large\n    max_size = 1024\n    if max(image.size) > max_size:\n        ratio = max_size / max(image.size)\n        new_size = (int(image.size[0] * ratio), int(image.size[1] * ratio))\n        image = image.resize(new_size, Image.Resampling.LANCZOS)\n    \n    # Prepare message format for pipeline\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"image\", \"image\": image},\n                {\"type\": \"text\", \"text\": EXTRACTION_PROMPT}\n            ]\n        }\n    ]\n    \n    # Generate with pipeline\n    output = pipe(messages, max_new_tokens=2048)\n    response = output[0][\"generated_text\"][-1][\"content\"]\n    \n    # Parse JSON from response\n    try:\n        start = response.find('[')\n        end = response.rfind(']') + 1\n        if start != -1 and end > start:\n            return json.loads(response[start:end])\n    except json.JSONDecodeError as e:\n        print(f\"JSON parsing error: {e}\")\n        print(f\"Raw response: {response[:500]}\")\n    \n    return []\n\n\ndef explain_lab_value(test_name: str, value: float, unit: str, \n                      reference_range: str, status: str) -> str:\n    \"\"\"Generate plain English explanation for a lab value.\"\"\"\n    \n    prompt = EXPLANATION_PROMPT.format(\n        test_name=test_name,\n        value=value,\n        unit=unit,\n        reference_range=reference_range,\n        status=status\n    )\n    \n    # Text-only query\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"text\", \"text\": prompt}\n            ]\n        }\n    ]\n    \n    output = pipe(messages, max_new_tokens=200)\n    response = output[0][\"generated_text\"][-1][\"content\"]\n    \n    return response\n\n\ndef analyze_report(image: Image.Image) -> dict:\n    \"\"\"Full analysis: extract values + generate explanations.\"\"\"\n    \n    print(\"Extracting lab values...\")\n    lab_values = extract_lab_values(image)\n    print(f\"Found {len(lab_values)} tests\")\n    \n    results = []\n    for i, val in enumerate(lab_values):\n        print(f\"Explaining {i+1}/{len(lab_values)}: {val.get('test_name', 'Unknown')}...\")\n        \n        explanation = explain_lab_value(\n            val.get('test_name', ''),\n            val.get('value', 0),\n            val.get('unit', ''),\n            val.get('reference_range', 'N/A'),\n            val.get('status', 'normal')\n        )\n        \n        results.append({\n            **val,\n            'explanation': explanation\n        })\n    \n    return {\n        'total_tests': len(results),\n        'normal': sum(1 for r in results if r.get('status') == 'normal'),\n        'abnormal': sum(1 for r in results if r.get('status') in ['high', 'low']),\n        'results': results\n    }"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Demo: Text-Only Explanations\n\nTest MedGemma's explanation capability with sample lab values (no image needed)."
  },
  {
   "cell_type": "code",
   "source": "# Demo: Explain sample lab values without needing an image\nsample_tests = [\n    {\"test_name\": \"Hemoglobin\", \"value\": 11.5, \"unit\": \"g/dL\", \"reference_range\": \"13.0-17.0\", \"status\": \"low\"},\n    {\"test_name\": \"Fasting Blood Sugar\", \"value\": 126, \"unit\": \"mg/dL\", \"reference_range\": \"70-100\", \"status\": \"high\"},\n    {\"test_name\": \"TSH\", \"value\": 2.5, \"unit\": \"mIU/L\", \"reference_range\": \"0.4-4.0\", \"status\": \"normal\"},\n]\n\nprint(\"Demo: Generating explanations for sample lab values\\n\")\nprint(\"=\"*60)\n\nfor test in sample_tests:\n    print(f\"\\n{test['test_name']}: {test['value']} {test['unit']} ({test['status'].upper()})\")\n    print(\"-\"*40)\n    \n    explanation = explain_lab_value(\n        test['test_name'],\n        test['value'],\n        test['unit'],\n        test['reference_range'],\n        test['status']\n    )\n    print(explanation)\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Option 1: Upload a file using Kaggle's file browser\n# Click \"Add Input\" in the right panel > Upload > Select your lab report image/PDF\n\n# Option 2: Use a sample from Kaggle datasets\n# from kaggle_datasets import KaggleDatasets\n\n# List uploaded files\nimport glob\nuploaded_files = glob.glob('/kaggle/input/**/*.*', recursive=True)\nprint(\"Available input files:\")\nfor f in uploaded_files[:10]:\n    print(f\"  {f}\")\n\n# Load your lab report image\n# Change this path to your uploaded file\nIMAGE_PATH = \"/kaggle/input/your-lab-report.jpg\"  # Update this path\n\nif os.path.exists(IMAGE_PATH):\n    image = Image.open(IMAGE_PATH).convert('RGB')\n    print(f\"Loaded image: {IMAGE_PATH}\")\n    print(f\"Image size: {image.size}\")\nelse:\n    print(f\"File not found: {IMAGE_PATH}\")\n    print(\"Upload a lab report using 'Add Input' in the right panel\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis\n",
    "results = analyze_report(image)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total tests: {results['total_tests']}\")\n",
    "print(f\"Normal: {results['normal']}\")\n",
    "print(f\"Abnormal: {results['abnormal']}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Display results with nice formatting\nfrom IPython.display import HTML, display\n\ndef display_results(results):\n    \"\"\"Display analysis results with nice HTML formatting.\"\"\"\n    html = \"<div style='font-family: Arial, sans-serif;'>\"\n    \n    for r in results['results']:\n        status = r.get('status', 'normal')\n        color = '#28a745' if status == 'normal' else '#dc3545' if status == 'high' else '#ffc107'\n        badge = 'Normal' if status == 'normal' else 'High' if status == 'high' else 'Low'\n        \n        html += f\"\"\"\n        <div style='border: 1px solid #ddd; border-left: 4px solid {color}; \n                    padding: 15px; margin: 10px 0; border-radius: 4px;'>\n            <div style='display: flex; justify-content: space-between; align-items: center;'>\n                <h3 style='margin: 0; color: #333;'>{r.get('test_name', 'Unknown')}</h3>\n                <span style='background: {color}; color: white; padding: 4px 12px; \n                             border-radius: 20px; font-size: 12px;'>{badge}</span>\n            </div>\n            <p style='font-size: 24px; margin: 10px 0; color: #333;'>\n                <strong>{r.get('value', 'N/A')}</strong> \n                <span style='font-size: 14px; color: #666;'>{r.get('unit', '')}</span>\n            </p>\n            <p style='color: #666; font-size: 13px; margin: 5px 0;'>\n                Reference: {r.get('reference_range', 'N/A')}\n            </p>\n            <hr style='border: none; border-top: 1px solid #eee; margin: 10px 0;'>\n            <p style='color: #444; line-height: 1.5;'>{r.get('explanation', 'No explanation available.')}</p>\n        </div>\n        \"\"\"\n    \n    html += \"</div>\"\n    display(HTML(html))\n\n# Display results if available\nif 'results' in dir() and results:\n    display_results(results)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Impact & Summary\n\n### Problem We're Solving\nIn India, millions of patients receive lab reports filled with medical jargon, confusing reference ranges, and numbers that mean nothing to them. This creates anxiety and prevents patients from taking proactive steps to improve their health.\n\n### How MedGemma Helps\nMedGemma 1.5 enables us to:\n1. **Extract** structured data from lab report images (OCR + understanding)\n2. **Interpret** values by comparing to reference ranges\n3. **Explain** results in simple, actionable language\n\n### Real-World Impact\n- **Accessibility**: Patients can understand their own health data\n- **Empowerment**: Informed patients make better health decisions\n- **Healthcare efficiency**: Doctors spend less time explaining basics\n- **Early intervention**: Patients notice abnormalities sooner\n\n### Technical Highlights\n- Uses MedGemma 1.5 4B instruction-tuned model\n- Handles multimodal input (image + text)\n- Trained on medical knowledge for accurate health information\n- Generates patient-friendly explanations\n\n### Future Roadmap\n- Mobile app for instant report scanning\n- Trend tracking across multiple reports\n- Regional language support (Hindi, Tamil, etc.)\n- Integration with hospital systems"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to JSON\n",
    "with open('analysis_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(\"Results saved to analysis_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}